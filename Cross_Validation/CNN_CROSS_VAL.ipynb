{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_CROSS_VAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dRgUFDBo9wV"
      },
      "source": [
        "from google.colab import  drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U6k6IlxrNqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d999daf3-9abd-4485-e819-1b37af3af226"
      },
      "source": [
        "drive.mount('/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTRZ2s-7qPI3"
      },
      "source": [
        "import pickle\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from keras import  regularizers\r\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvTYyuK1qij7"
      },
      "source": [
        "def file_reader(file_location):\r\n",
        "    if(file_location.endswith('csv')):\r\n",
        "        return pd.read_csv( file_location , engine = 'python')\r\n",
        "    elif (file_location.endswith('tsv')):\r\n",
        "        return pd.read_csv( file_location , engine = 'python' ,sep = '\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-1zJte6qinM"
      },
      "source": [
        "import tensorflow\r\n",
        "import gc\r\n",
        "\r\n",
        "# Reset Keras Session\r\n",
        "def reset_keras():\r\n",
        "    sess = tf.compat.v1.Session()\r\n",
        "    tf.keras.backend.clear_session()\r\n",
        "    sess.close()\r\n",
        "    sess = tf.compat.v1.Session()\r\n",
        "\r\n",
        "    try:\r\n",
        "        del model1 # this is from global space - change this as you need\r\n",
        "    except:\r\n",
        "        pass\r\n",
        "    try:\r\n",
        "        del model0 # this is from global space - change this as you need\r\n",
        "    except:\r\n",
        "        pass\r\n",
        "\r\n",
        "    print(gc.collect()) # if it does something you should see a number as output\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8pmetHzqip1"
      },
      "source": [
        "def generate_model(input_len, embeddings):\r\n",
        "    model = tf.keras.Sequential([\r\n",
        "        tf.keras.layers.Embedding( \r\n",
        "                                   input_dim = embeddings.shape[0], \r\n",
        "                                   output_dim = embedding_dim, \r\n",
        "                                   weights = [embeddings], \r\n",
        "                                   input_length = input_len , \r\n",
        "                                   trainable = False\r\n",
        "                                  ),\r\n",
        "        tf.keras.layers.Conv1D( \r\n",
        "                                filters=128,\r\n",
        "                                kernel_size=4,\r\n",
        "                                activation='relu',\r\n",
        "                              ),\r\n",
        "        tf.keras.layers.Conv1D( \r\n",
        "                                filters=8,\r\n",
        "                                kernel_size=4,\r\n",
        "                                activation='relu',\r\n",
        "                              ),\r\n",
        "        tf.keras.layers.Conv1D( \r\n",
        "                                filters=256,\r\n",
        "                                kernel_size=4,\r\n",
        "                                activation='relu',\r\n",
        "                                #kernel_regularizer = tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\r\n",
        "                                #bias_regularizer = tf.keras.regularizers.l2(1e-4),\r\n",
        "                                #activity_regularizer = tf.keras.regularizers.l2(1e-5)\r\n",
        "                              ),\r\n",
        "        tf.keras.layers.GlobalAvgPool1D(),\r\n",
        "        tf.keras.layers.Dropout(0.4),\r\n",
        "        tf.keras.layers.Dense(4,activation='sigmoid'),\r\n",
        "        tf.keras.layers.Dense(1,activation='sigmoid')\r\n",
        "    ])\r\n",
        "    model.compile( loss='binary_crossentropy' , optimizer = 'adam', metrics=['acc'] )\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fogS99NQqisY"
      },
      "source": [
        "def train_model(X, Y, embeddings, num_epoch):\r\n",
        "    model1 = generate_model(X.shape[1], embeddings)\r\n",
        "    model0 = generate_model(X.shape[1], embeddings)\r\n",
        "    model1.fit(X, (Y == 1).astype(int), epochs = num_epoch , shuffle = True , batch_size = 200, verbose=0)\r\n",
        "    model0.fit(X, (Y == 0).astype(int), epochs = num_epoch , shuffle = True , batch_size = 200, verbose=0)\r\n",
        "    return (model1,model0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3tghLC1qpj5"
      },
      "source": [
        "def predict_model(model1, model0, X):\r\n",
        "    pred1 = model1.predict(X)\r\n",
        "    pred0 = model0.predict(X)\r\n",
        "    return (pred1.T[0] > pred0.T[0]).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdhi3EADqpmc"
      },
      "source": [
        "def train_and_test(X_train, X_test, Y_train, Y_test, num_epoch):\r\n",
        "    model1,model0 = train_model(X_train, Y_train, embeddings, num_epoch)\r\n",
        "    ptrain = predict_model(model1, model0, X_train)\r\n",
        "    ptest  = predict_model(model1, model0, X_test)\r\n",
        "    train_score = np.mean( (ptrain == Y_train).astype(int) )         \r\n",
        "    test_score  = np.mean( (ptest == Y_test).astype(int) ) \r\n",
        "    return train_score, test_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne8r6KQIqppN"
      },
      "source": [
        "def gen_LOOCV_sets(X, Y, i):\r\n",
        "    X_train = np.delete(X, i, axis = 0)\r\n",
        "    X_test  = np.array( [X[i]] )\r\n",
        "    Y_train = df_essays.drop(df_essays.index[i])\r\n",
        "    Y_test  = df_essays.iloc[i]\r\n",
        "    return (X_train, X_test, Y_train, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFxpxVoLqpr4"
      },
      "source": [
        "def cross_val_CNN(X, Y, embeddings, num_epoch, left, right):\r\n",
        "    train_scores, test_scores = pd.DataFrame(), pd.DataFrame()\r\n",
        "    \r\n",
        "    for i in range(left,right):\r\n",
        "        \r\n",
        "        print('Iteration',i, end='  :')\r\n",
        "        \r\n",
        "        (X_train, X_test, Y_train, Y_test) = gen_LOOCV_sets(X, Y, i)\r\n",
        "        dtrain,dtest = {}, {}\r\n",
        "        dtrain['i'] = i\r\n",
        "        dtest['i']  = i\r\n",
        "        for trait in trait_names:\r\n",
        "            \r\n",
        "            print(trait,end=' - ')\r\n",
        "            \r\n",
        "            train_score, test_score = train_and_test(X_train, X_test, Y_train[trait], Y_test[trait], num_epoch)\r\n",
        "            dtrain[trait] = train_score\r\n",
        "            dtest[trait]  = test_score\r\n",
        "        \r\n",
        "        train_scores = train_scores.append(dtrain,ignore_index = True)\r\n",
        "        test_scores  = test_scores.append(dtest,ignore_index = True)   \r\n",
        "        print(' Done\\n')\r\n",
        "        \r\n",
        "        train_scores.to_csv('/drive/My Drive/Files/CNN_train_score_' + str(left) + '.csv')\r\n",
        "        test_scores.to_csv('/drive/My Drive/Files/CNN_test_score_' + str(left) + '.csv')\r\n",
        "        \r\n",
        "        reset_keras()\r\n",
        "    return train_scores,test_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaDv2-v3uEYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd35553-e253-4737-f286-9098fa316751"
      },
      "source": [
        "1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1GQ66JEqivI"
      },
      "source": [
        "trait_names = ['cEXT' , 'cNEU' , 'cCON','cAGR' , 'cOPN']\r\n",
        "embedding_dim         = 300\r\n",
        "num_epochs            = 20\r\n",
        "batch_size            = 100\r\n",
        "max_length            = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS5O-RtSoW2D"
      },
      "source": [
        "with open( '/drive/My Drive/Files/essays.pickle', 'rb' ) as handle:\r\n",
        "    essays = pickle.load(handle)\r\n",
        "     \r\n",
        "with open( '/drive/My Drive/Files/embeddings.pickle', 'rb') as handle:\r\n",
        "    embeddings = pickle.load(handle)\r\n",
        "    \r\n",
        "df_essays = file_reader( '/drive/My Drive/Files/essays.csv' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtsFCI7iovJk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-wcV_d-r7an",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b19c8f-5c2e-4095-9646-5c622e75cca9"
      },
      "source": [
        "train_score,test_score = cross_val_CNN(essays, df_essays, embeddings, 80, left = 1394, right = 1400)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1394  :cEXT - cNEU - cCON - cAGR - cOPN -  Done\n",
            "\n",
            "63791\n",
            "Iteration 1395  :cEXT - cNEU - cCON - cAGR - cOPN -  Done\n",
            "\n",
            "44109\n",
            "Iteration 1396  :cEXT - cNEU - cCON - cAGR - cOPN -  Done\n",
            "\n",
            "44109\n",
            "Iteration 1397  :cEXT - cNEU - cCON - cAGR - cOPN -  Done\n",
            "\n",
            "44109\n",
            "Iteration 1398  :cEXT - cNEU - cCON - cAGR - cOPN -  Done\n",
            "\n",
            "44109\n",
            "Iteration 1399  :cEXT - cNEU - cCON - cAGR - cOPN -  Done\n",
            "\n",
            "44109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCZgpbcDHrtO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}